using System.Collections;
using System.Collections.Generic;
using DG.Tweening;
using UnityEditor.Rendering;
using UnityEngine;
using UnityEngine.UI;

public class IO_Manager : MonoBehaviour
{
    public static IO_Manager instance;
    public InputField inputField;
    public Text subtitleText;
    public bool isTesting;
    public string testinput;
    public VoskSpeechToText voiceInput;

    public Agent currentActiveAgent;
    [TextArea(1, 5)]
    public string sentence, inputStructure;

    public Transform content;
    public Text textPrefab;

    private void Awake()
    {
        instance = this;
    }

    private void Start()
    {
        voiceInput.OnTranscriptionResult += onVoiceComplete;
    }
    public void UpdateSentence(string str) // user input from typing
    {
        sentence = str;
    }

    private void SetStructure(ActionHandler actionList, Interactables objectsList)
    {
        // Setting up the input format as defined in SURD AI

        string actions = "Available actions: ";
        foreach (var action in actionList.actions)
        {
            actions += action.actionName + " (" + action.description + "), ";
        }

        string objects = "Objects list: ";
        foreach (var obj in objectsList._objects)
        {
            objects += obj.objectName + " (" + obj.description + "), ";
        }

        string personality = "Personality / Backstory: Name is " + currentActiveAgent.characterName + ", " + currentActiveAgent.background + ", ";
        string userInput = "Natural language input: " + sentence;

        string format = actions + objects + personality + userInput;
        inputStructure = format;

    }

    public async void StartProcess()
    {
        print("Start Processing..");
        SetStructure(currentActiveAgent.GetComponent<ActionHandler>(), Interactables.instance);


        SURD_AI.ResponseData responseData;
        if (isTesting)
        {
            responseData = await SURD_AI.Instance.CallAsyncAIModelTest(testinput);
        }
        else
        {
            responseData = await SURD_AI.Instance.CallAsyncAIModel(inputStructure);
        }
        
        // output recieved from SURD AI is sent back to environemnt to match
        Processor p = new Processor(responseData, Interactables.instance);
        GameObject obj = new GameObject("processor");
        Processor pro = obj.AddComponent<Processor>();
        pro = p;
        // p is an object which found all matches from the environment
        ShowSubtitle(p.verbalResponse);
        currentActiveAgent.GetComponent<ActionHandler>().DoAction(p);
    }

    public void ShowSubtitle(string str)
    {
        // str is the verbal response came from SURD AI
        string subtitle = currentActiveAgent.characterName + ": " + str;
        

        // this is used to define animation of text
        // (animation is like a character by character with the duration of 0.1 seconds)
        subtitleText.text = "";
        subtitleText.DOText(subtitle, 0.1f);


        // subtitle will disappear after 5 seconds 
        subtitleText.DOText("", 0).SetDelay(5);
    }
    private void onVoiceComplete(string dialogues) // function is called from vosk and sending user input generated by vosk as an arguement
    {
        var result = new RecognitionResult(dialogues);
        print("Best Result: " + result.Phrases[0].Text);

        // storing the best/highest confidence of recognized words
        string str = result.Phrases[0].Text;
        UserInput(str);
    }

    private void UserInput(string str) 
    {
        string subtitle = "You: " + str;

        // displaying user input on top left of the screen
        Text text = Instantiate(textPrefab, content);
        text.text = subtitle;

        UpdateSentence(str);
        StartProcess();
    }


}